{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import List, Tuple\n",
    "from scipy.spatial.distance import euclidean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sorted_nearest_cluster_from_atypical_point(atypical_point: pd.Series, cluster_centers: pd.DataFrame) -> List[Tuple[int, float]]:\n",
    "    distances = []\n",
    "    for index, row in cluster_centers.iterrows():\n",
    "        dist = euclidean(atypical_point, row.drop('cluster'))\n",
    "        distances.append((row['cluster'], dist))\n",
    "    \n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    return distances\n",
    "\n",
    "\n",
    "def calculate_clusters_centers_distance(cluster_start, cluster_target, cluster_centers: pd.DataFrame) -> float:\n",
    "    cluster_start_point = cluster_centers[cluster_centers[\"cluster\"] == cluster_start].drop('cluster', axis=1).iloc[0]\n",
    "    cluster_target_point = cluster_centers[cluster_centers[\"cluster\"] == cluster_target].drop('cluster', axis=1).iloc[0]\n",
    "\n",
    "    return euclidean(cluster_start_point, cluster_target_point)\n",
    "\n",
    "\n",
    "def get_sorted_nearest_clusters(start_cluster, cluster_centers: pd.DataFrame) -> List[Tuple[int, float]]:\n",
    "    all_clusters = cluster_centers['cluster'].unique()\n",
    "    distances = []\n",
    "\n",
    "    for cluster in all_clusters:\n",
    "        if cluster != start_cluster:\n",
    "            distance = calculate_clusters_centers_distance(start_cluster, cluster, cluster_centers)\n",
    "            distances.append((cluster, distance))\n",
    "\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    return distances\n",
    "\n",
    "def get_cluster_row_by_id(cluster_id: int, cluster_centers: pd.DataFrame) -> pd.Series:\n",
    "    cluster_row = cluster_centers[cluster_centers['cluster'] == cluster_id]\n",
    "\n",
    "    if not cluster_row.empty:\n",
    "        return cluster_row.iloc[0]\n",
    "    else:\n",
    "        return None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_center = pd.read_csv(\"./data/cluster_center.csv\")\n",
    "clustered_data = pd.read_csv(\"./data/spotify_songs_clustered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15405 entries, 0 to 15404\n",
      "Data columns (total 20 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   danceability             15405 non-null  float64\n",
      " 1   energy                   15405 non-null  float64\n",
      " 2   key                      15405 non-null  float64\n",
      " 3   loudness                 15405 non-null  float64\n",
      " 4   speechiness              15405 non-null  float64\n",
      " 5   acousticness             15405 non-null  float64\n",
      " 6   instrumentalness         15405 non-null  float64\n",
      " 7   valence                  15405 non-null  float64\n",
      " 8   tempo                    15405 non-null  float64\n",
      " 9   lyrics_sentiment         15405 non-null  float64\n",
      " 10  album_name_sentiment     15405 non-null  float64\n",
      " 11  track_name_sentiment     15405 non-null  float64\n",
      " 12  playlist_name_sentiment  15405 non-null  float64\n",
      " 13  genre_edm                15405 non-null  bool   \n",
      " 14  genre_latin              15405 non-null  bool   \n",
      " 15  genre_pop                15405 non-null  bool   \n",
      " 16  genre_r&b                15405 non-null  bool   \n",
      " 17  genre_rap                15405 non-null  bool   \n",
      " 18  genre_rock               15405 non-null  bool   \n",
      " 19  cluster                  15405 non-null  int64  \n",
      "dtypes: bool(6), float64(13), int64(1)\n",
      "memory usage: 1.7 MB\n"
     ]
    }
   ],
   "source": [
    "clustered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['genre_edm', 'genre_latin', 'genre_pop', 'genre_r&b', 'genre_rap', 'genre_rock']:\n",
    "    clustered_data[col] = clustered_data[col].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Suponiendo que 'data' es tu DataFrame y 'cluster' es la columna objetivo\n",
    "X = clustered_data.drop('cluster', axis=1)\n",
    "y = clustered_data['cluster']\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento, validación y prueba\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica si hay NaNs y los reemplaza por un número, por ejemplo, 0\n",
    "X_train = X_train.fillna(0)\n",
    "X_val = X_val.fillna(0)\n",
    "X_test = X_test.fillna(0)\n",
    "\n",
    "# Asegúrate de que todos los datos son numéricos\n",
    "X_train = X_train.apply(pd.to_numeric)\n",
    "X_val = X_val.apply(pd.to_numeric)\n",
    "X_test = X_test.apply(pd.to_numeric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "\n",
    "# Número de características de entrada\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Número de clusters (número de neuronas en la capa de salida)\n",
    "num_clusters = len(y.unique())\n",
    "\n",
    "# Crear modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_clusters, activation='softmax'))\n",
    "\n",
    "# Compilar modelo\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_filtered = X_train[y_train != -1]\n",
    "y_train_filtered = y_train[y_train != -1]\n",
    "\n",
    "X_val_filtered = X_val[y_val != -1]\n",
    "y_val_filtered = y_val[y_val != -1]\n",
    "\n",
    "X_test_filtered = X_test[y_test != -1]\n",
    "y_test_filtered = y_test[y_test != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lp109\\AppData\\Local\\Temp\\ipykernel_2560\\910705944.py\", line 1, in <module>\n      history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=10)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of -1 which is outside the valid range of [0, 29).  Label values: 2 0 -1 -1 -1 -1 2 -1 -1 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1027]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\lp109\\OneDrive\\Documentos\\0lps\\01 U\\0LaU\\000Octavo semestre\\Deep Learning\\Proyecto final\\cluster_prediction.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/lp109/OneDrive/Documentos/0lps/01%20U/0LaU/000Octavo%20semestre/Deep%20Learning/Proyecto%20final/cluster_prediction.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\lp109\\AppData\\Roaming\\Python\\Python311\\site-packages\\IPython\\core\\interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\lp109\\AppData\\Local\\Temp\\ipykernel_2560\\910705944.py\", line 1, in <module>\n      history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=100, batch_size=10)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\training.py\", line 1109, in compute_loss\n      return self.compiled_loss(\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 142, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 268, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\losses.py\", line 2078, in sparse_categorical_crossentropy\n      return backend.sparse_categorical_crossentropy(\n    File \"c:\\Users\\lp109\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\backend.py\", line 5660, in sparse_categorical_crossentropy\n      res = tf.nn.sparse_softmax_cross_entropy_with_logits(\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of -1 which is outside the valid range of [0, 29).  Label values: 2 0 -1 -1 -1 -1 2 -1 -1 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_1027]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train_filtered, y_train_filtered, validation_data=(X_val_filtered, y_val_filtered), epochs=100, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Número de características de entrada\n",
    "input_dim = X_train.shape[1]\n",
    "\n",
    "# Número de clusters (número de neuronas en la capa de salida)\n",
    "num_clusters = len(y.unique())\n",
    "\n",
    "# Crear modelo\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(num_clusters, activation='softmax'))\n",
    "\n",
    "# Compilar modelo\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('mi_modelo_cluster.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
